In this work, I compared the performance of five different classifiers in classifying sentiment and then used six different feature selectors on the best-performing classifiers.  The best classifier was a RF classifier, while among the NB classifiers the Bernoulli estimator worked the best.  Feature selection offered only marginal improvement upon the base results.  For the NB Bernoulli classifier, a KB algorithm with an F-test scoring function performed the best, while for the RF classifier the best feature selector is a toss between KB with a $\chi^2$ scoring function and a ``by hand'' culling of the feature set that I performed.  Two of the feature selectors (KB with a mutual information scoring function and RFE) took too long to run with the RF classifier (which already took a long time to run relative to the other classifiers) to be shown in this work.

A primary future direction for this work is to increase the size of the training data.  The fact that feature selection did not do much seems to indicated that the training data have not yet saturated the useful feature set.  Another useful future direction is to expand the features from the training data already available, e.g., incorporate bigrams and not just unigrams.  A final suggestion is to study possible synergies between the different classifiers; perhaps using multiple of them together would reveal a whole that is greater than the sum of its parts.